{"cells":[{"cell_type":"markdown","id":"cfc52381","metadata":{"id":"cfc52381"},"source":["[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/biodatlab/deep-learning-skooldio/blob/master/student_notebooks/03_handwritten_recognition_explore.ipynb)\n","\n","## **Thai-digit handwritten classification with Pytorch: Student Notebook Exploration**\n","\n","This notebook contains exploration of the \"Thai-digit handwritten classification\" including\n","- Customizing model\n","    - Adding layers\n","    - Adding dropout layer\n","- Adding image augmentation"]},{"cell_type":"markdown","id":"3aa56f94","metadata":{"id":"3aa56f94"},"source":["## **Download and clean the dataset from the repository**\n","\n","- We have downloaded the data from https://github.com/kittinan/thai-handwriting-number by cloning the repository\n","- Remove files that have character mismatch (as suggested by the the creator)\n","- Then, we put the cleaned data at https://github.com/biodatlab/deep-learning-skooldio"]},{"cell_type":"code","execution_count":null,"id":"f7deb2f6","metadata":{"id":"f7deb2f6"},"outputs":[],"source":["!git clone https://github.com/biodatlab/deep-learning-skooldio"]},{"cell_type":"markdown","id":"29268a34","metadata":{"id":"29268a34"},"source":["After cloning the repository, check that `deep-learning-skooldio` should appear in the directory."]},{"cell_type":"code","execution_count":null,"id":"2ad2a443","metadata":{"id":"2ad2a443"},"outputs":[],"source":["import os\n","import os.path as op\n","from glob import glob\n","from pathlib import Path\n","import random\n","from PIL import Image\n","from collections import Counter\n","from torch.utils.data import ConcatDataset\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"]},{"cell_type":"code","execution_count":null,"id":"64ce2573","metadata":{"id":"64ce2573"},"outputs":[],"source":["directory = \"deep-learning-skooldio/\"\n","paths = glob(op.join(directory, \"thai-handwritten-dataset\", \"*\", \"*\"))\n","num_samples = len(paths)\n","print(\"Number of samples\", num_samples)"]},{"cell_type":"code","execution_count":null,"id":"6aa0f5b4","metadata":{"id":"6aa0f5b4"},"outputs":[],"source":["from tqdm.auto import tqdm\n","from sklearn.model_selection import train_test_split\n","import shutil\n","\n","train_paths, validation_paths = train_test_split(paths, test_size=0.1, random_state=42)\n","for i in range(10):\n","    os.makedirs(f\"data/train/{i}\", exist_ok=True)\n","    os.makedirs(f\"data/validation/{i}\", exist_ok=True)"]},{"cell_type":"code","execution_count":null,"id":"fe1d237b","metadata":{"id":"fe1d237b"},"outputs":[],"source":["def copy_to_destination(src_paths, dst_path: str = \"data/train/\"):\n","    for path in tqdm(src_paths):\n","        path = Path(path)\n","        parent_dir = path.parent.name\n","        shutil.copy(path, op.join(dst_path, parent_dir, path.name))"]},{"cell_type":"code","execution_count":null,"id":"af9064ae","metadata":{"id":"af9064ae"},"outputs":[],"source":["copy_to_destination(train_paths, \"data/train/\")\n","copy_to_destination(validation_paths, \"data/validation/\")"]},{"cell_type":"code","execution_count":null,"id":"molxWFBdMq55","metadata":{"id":"molxWFBdMq55"},"outputs":[],"source":["len(glob(\"data/train/*/*\")), len(glob(\"data/validation/*/*\"))"]},{"cell_type":"markdown","id":"ae55f494","metadata":{"id":"ae55f494"},"source":["## **Create a custom dataset and a dataloader**"]},{"cell_type":"code","execution_count":null,"id":"d0b69d68","metadata":{"id":"d0b69d68"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"id":"2dbd4be3","metadata":{"id":"2dbd4be3"},"outputs":[],"source":["\n","transform = transforms.Compose([\n","    transforms.Resize((28, 28)),\n","    transforms.Grayscale(),\n","    transforms.ToTensor()\n","])"]},{"cell_type":"code","execution_count":null,"id":"09eb4140","metadata":{"id":"09eb4140"},"outputs":[],"source":["class ThaiDigitDataset(Dataset):\n","    def __init__(self, img_dir: str, transform=None):\n","        self.img_dir = img_dir\n","        self.transform = transform\n","        self.img_labels = [(p, Path(p).parent.name) for p in glob(op.join(img_dir, \"*\", \"*\"))]\n","\n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        image, label = self.img_labels[idx]\n","        label = int(label)\n","        image = Image.open(image)\n","        if self.transform:\n","            image = 1 - self.transform(image)\n","        return image, label"]},{"cell_type":"code","execution_count":null,"id":"f1175f91","metadata":{"id":"f1175f91"},"outputs":[],"source":["train_thaidigit_dataset = ThaiDigitDataset(\"data/train/\", transform=transform)\n","val_thaidigit_dataset = ThaiDigitDataset(\"data/validation/\", transform=transform)"]},{"cell_type":"code","execution_count":null,"id":"d4f83af9","metadata":{"id":"d4f83af9"},"outputs":[],"source":["train_loader = DataLoader(train_thaidigit_dataset, batch_size=16, shuffle=True)\n","val_loader = DataLoader(val_thaidigit_dataset, batch_size=16, shuffle=False)"]},{"cell_type":"markdown","id":"275542ac","metadata":{"id":"275542ac"},"source":["## **Create the model**"]},{"cell_type":"code","execution_count":null,"id":"abbd30d0","metadata":{"id":"abbd30d0"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ThaiDigitNet(nn.Module):\n","    def __init__(self):\n","        super(ThaiDigitNet, self).__init__()\n","        self.fc1 = nn.Linear(28 * 28, 100)\n","        self.fc2 = nn.Linear(100, 10)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28 * 28)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"markdown","id":"f0455ef9","metadata":{"id":"f0455ef9"},"source":["## **Train the model**"]},{"cell_type":"code","execution_count":null,"id":"r61vWix7nfgl","metadata":{"id":"r61vWix7nfgl"},"outputs":[],"source":["# Create training loop function\n","def train(model, n_epochs, loss_function, optimizer, train_loader, validation_loader):\n","    training_logs = {\"train_loss\": [],  \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n","    print(\"-\"*80)\n","    for epoch in range(1, n_epochs+1):\n","        # training\n","        model.train()\n","        train_loss, correct = 0, 0\n","        for images, labels in train_loader:\n","            pred = model(images)\n","            loss = loss_function(pred, labels)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","            correct += (pred.argmax(1) == labels).float().sum().item()\n","        # save training logs\n","        training_logs[\"train_loss\"].append(train_loss/ len(train_loader))\n","        training_logs[\"train_acc\"].append(correct / len(train_loader.dataset))\n","\n","        # validation\n","        model.eval()\n","        val_loss, correct = 0, 0\n","        for images, labels in validation_loader:\n","            pred = model(images)\n","            val_loss += loss_function(pred, labels).item()\n","            correct += (pred.argmax(1) == labels).float().sum().item()\n","        # save validation logs\n","        training_logs[\"val_loss\"].append(val_loss/ len(val_loader))\n","        training_logs[\"val_acc\"].append(correct / len(validation_loader.dataset))\n","\n","        print(f\"Epochs {epoch}\".ljust(10),\n","              f\"train loss {training_logs['train_loss'][-1]:.5f}\",\n","              f\"train acc {training_logs['train_acc'][-1]:.5f}\",\n","\n","              f\"val loss {training_logs['val_loss'][-1]:.5f}\",\n","              f\"val acc {training_logs['val_acc'][-1]:.5f}\",\n","              )\n","        print(\"-\"*80)\n","    return model, training_logs\n"]},{"cell_type":"code","execution_count":null,"id":"amMGdYvkAg0c","metadata":{"id":"amMGdYvkAg0c"},"outputs":[],"source":["n_epoch = 100\n","\n","net = ThaiDigitNet() # Initialize the model\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n","net, net_history = train(net, n_epoch, loss_fn, optimizer, train_loader, val_loader)"]},{"cell_type":"code","execution_count":null,"id":"j__w3mymCPJh","metadata":{"id":"j__w3mymCPJh"},"outputs":[],"source":["def plot_graph(history):\n","    fig, (ax1, ax2) = plt.subplots(1, 2)\n","    fig.set_figwidth(10)\n","    fig.suptitle(\"Train vs Validation\")\n","    ax1.plot(history[\"train_acc\"], label=\"Train\")\n","    ax1.plot(history[\"val_acc\"], label=\"Validation\")\n","    ax1.legend()\n","    ax1.set_title(\"Accuracy\")\n","\n","    ax2.plot(history[\"train_loss\"], label=\"Train\")\n","    ax2.plot(history[\"val_loss\"], label=\"Validation\")\n","    ax2.legend()\n","    ax2.set_title(\"Loss\")\n","    fig.show()"]},{"cell_type":"code","execution_count":null,"id":"e8dAIHcnCIJA","metadata":{"id":"e8dAIHcnCIJA"},"outputs":[],"source":["plot_graph(net_history)"]},{"cell_type":"markdown","id":"sMvIE0JbRd0Q","metadata":{"id":"sMvIE0JbRd0Q"},"source":["We can observe \"overfitting\" as the model learns to predict the training set well but perform worse in validation set"]},{"cell_type":"markdown","id":"2a0229f1","metadata":{"id":"2a0229f1"},"source":["## **Evaluate the model**"]},{"cell_type":"code","execution_count":null,"id":"5b41a1c8","metadata":{"id":"5b41a1c8"},"outputs":[],"source":["# Create evaluation function for the model\n","def evaluate(val_dir, model):\n","    model.eval()\n","    paths = glob(op.join(val_dir, \"*\", \"*\"))\n","    predictions = []\n","    for idx, path in enumerate(paths):\n","        img = 1 - transform(Image.open(path))\n","        pred = model(img)\n","        predictions.append({\n","            \"path\": path,\n","            \"prediction\": int(pred.argmax(dim=1).item()),\n","            \"label\": int(Path(path).parent.name)\n","        })\n","\n","    results = pd.DataFrame(predictions)\n","    # Calculate accuracy\n","    accuracy = (results.prediction == results.label).sum() / len(results)\n","    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n","    return results"]},{"cell_type":"code","execution_count":null,"id":"3WOPs_x_Amap","metadata":{"id":"3WOPs_x_Amap"},"outputs":[],"source":["pred_df = evaluate(\"data/validation/\", net)\n","pred_df.head(3)"]},{"cell_type":"code","execution_count":null,"id":"goWDOiKlA0oA","metadata":{"id":"goWDOiKlA0oA"},"outputs":[],"source":["# Show some random images with their predicted number\n","sample_path = glob(\"data/validation/*/*.png\")[50]\n","img = Image.open(sample_path)\n","img = (1 - transform(img)).squeeze(0)\n","pred = net(img)\n","pred = int(pred.argmax(dim=1))\n","true_class = Path(sample_path).parent.name\n","\n","plt.title(\"Predicted class = {}, True class = {}\".format(pred, true_class))\n","plt.imshow(img, cmap=\"gray\")\n","plt.show()"]},{"cell_type":"markdown","id":"-F6H4tFLmUCG","metadata":{"id":"-F6H4tFLmUCG"},"source":["## **Train neural netowrk model with more layers**"]},{"cell_type":"code","execution_count":null,"id":"IHMQhUJCg6QU","metadata":{"id":"IHMQhUJCg6QU"},"outputs":[],"source":["# TODO: Create neural network with more layers\n","class ThaiDigitMoreLayers(nn.Module):\n","    def __init__(self):\n","        super(ThaiDigitMoreLayers, self).__init__()\n","        # TODO: Create layers\n","\n","    def forward(self, x):\n","        # TODO: forward pass\n","        return x"]},{"cell_type":"code","execution_count":null,"id":"TyFPAWPCFzN7","metadata":{"id":"TyFPAWPCFzN7"},"outputs":[],"source":["n_epochs = 100\n","\n","more_layers_model = ThaiDigitMoreLayers()\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(more_layers_model.parameters(), lr=0.01)\n","\n","more_layers_model, more_layers_model_history = train(\n","    more_layers_model, n_epochs, loss_fn, optimizer, train_loader, val_loader\n",")"]},{"cell_type":"code","execution_count":null,"id":"xt-SoyPCHDH5","metadata":{"id":"xt-SoyPCHDH5"},"outputs":[],"source":["pred_df = evaluate(\"data/validation/\", more_layers_model)\n","pred_df.head(3)"]},{"cell_type":"code","execution_count":null,"id":"N5uZG7ekArVW","metadata":{"id":"N5uZG7ekArVW"},"outputs":[],"source":["plot_graph(more_layers_model_history)"]},{"cell_type":"markdown","id":"43ccb6fc","metadata":{"id":"43ccb6fc"},"source":["The training accuracy of the model is higher than the validation accuracy.\n","This means that the model is overfitting the training data.\n","We can try to reduce the overfitting by adding regularization ."]},{"cell_type":"markdown","id":"65fb58d7","metadata":{"id":"65fb58d7"},"source":["## **Regularization with Dropout**\n","\n","Dropout is one of the techniques used to prevent overfitting. Here, we can train the model for more epochs to observe the loss curve."]},{"cell_type":"code","execution_count":null,"id":"a8e819c7","metadata":{"id":"a8e819c7"},"outputs":[],"source":["# TODO: Add Dropout layer to the previous neural network\n","class DropoutThaiDigit(nn.Module):\n","    def __init__(self):\n","        super(DropoutThaiDigit, self).__init__()\n","        # TODO: Create layers\n","\n","    def forward(self, x):\n","        # TODO: Create forward pass\n","        return x"]},{"cell_type":"code","execution_count":null,"id":"hG2gLwxzAstf","metadata":{"id":"hG2gLwxzAstf"},"outputs":[],"source":["n_epochs = 100\n","drop_model = DropoutThaiDigit()  # Initialize a model\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(drop_model.parameters(), lr=0.01)\n","\n","dropout_model, dropout_model_history = train(drop_model, n_epochs, loss_fn, optimizer, train_loader, val_loader)"]},{"cell_type":"code","execution_count":null,"id":"mNcSAyj2AuAC","metadata":{"id":"mNcSAyj2AuAC"},"outputs":[],"source":["pred_df = evaluate(\"data/validation/\", dropout_model)\n","pred_df.head(3)"]},{"cell_type":"code","execution_count":null,"id":"Ys7_0F5tIYnn","metadata":{"id":"Ys7_0F5tIYnn"},"outputs":[],"source":["plot_graph(dropout_model_history)"]},{"cell_type":"markdown","id":"b611d20b","metadata":{"id":"b611d20b"},"source":["Now the gap between the training accuracy and validation accuracy is smaller than before."]},{"cell_type":"markdown","id":"_R305_c-sBGn","metadata":{"id":"_R305_c-sBGn"},"source":["## **Image Augmentation**\n","\n","Image augmentation is a technique used to artificially increase the size of a training dataset by creating modified versions of existing images."]},{"cell_type":"code","execution_count":null,"id":"rKRgszrQNwPw","metadata":{"id":"rKRgszrQNwPw"},"outputs":[],"source":["# TODO: Add image augmentation in `train_transform`\n","\n","train_transform = transforms.Compose([\n","    transforms.Resize((28, 28)),\n","    transforms.Grayscale(),\n","    # add RandomAffine transform here\n","    transforms.ToTensor(),\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.Resize((28, 28)),\n","    transforms.Grayscale(),\n","    transforms.ToTensor(),\n","])"]},{"cell_type":"code","execution_count":null,"id":"PTsA7pkYKz4x","metadata":{"id":"PTsA7pkYKz4x"},"outputs":[],"source":["path = glob(\"deep-learning-skooldio/thai-handwritten-dataset/*/*\")[30]\n","img = Image.open(path)\n","\n","# TODO: Transform image using `train_transform`\n","transformed_img =  # Add your code here\n","\n","plt.imshow(transformed_img, cmap=\"gray\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"qtpgbABlefBj","metadata":{"id":"qtpgbABlefBj"},"outputs":[],"source":["train_thaidigit_dataset = ThaiDigitDataset(\"data/train/\", transform=train_transform)\n","val_thaidigit_dataset = ThaiDigitDataset(\"data/validation/\", transform=val_transform)"]},{"cell_type":"code","execution_count":null,"id":"DWmjYCRmfOfH","metadata":{"id":"DWmjYCRmfOfH"},"outputs":[],"source":["train_dataloader = DataLoader(train_thaidigit_dataset, batch_size=16, shuffle=True)\n","val_dataloader = DataLoader(val_thaidigit_dataset, batch_size=16, shuffle=False)"]},{"cell_type":"code","execution_count":null,"id":"d0OHv65iJgHs","metadata":{"id":"d0OHv65iJgHs"},"outputs":[],"source":["# Let's train the model with augmented data\n","n_epochs = 150\n","augmented_model = DropoutThaiDigit()  # Initialize the model\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(augmented_model.parameters(), lr=0.01)\n","\n","augmented_model, augmented_model_history = train(\n","    augmented_model, n_epochs, loss_fn, optimizer, train_dataloader, val_dataloader\n",")"]},{"cell_type":"code","execution_count":null,"id":"0_lbTJOXJheG","metadata":{"id":"0_lbTJOXJheG"},"outputs":[],"source":["# Evaluate the new model with old dataset.\n","pred_df = evaluate(\"data/validation/\", augmented_model)\n","pred_df.head(3)"]},{"cell_type":"code","execution_count":null,"id":"1kByhfphJi4M","metadata":{"id":"1kByhfphJi4M"},"outputs":[],"source":["plot_graph(augmented_model_history)"]},{"cell_type":"code","execution_count":null,"id":"GPwNfAB_Jj7L","metadata":{"id":"GPwNfAB_Jj7L"},"outputs":[],"source":["# Confusion matrix\n","cm = confusion_matrix(pred_df.label, pred_df.prediction, labels=range(10))\n","display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(10))\n","display.plot()\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":5}