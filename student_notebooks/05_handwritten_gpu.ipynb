{"cells":[{"cell_type":"markdown","id":"cfc52381","metadata":{"id":"cfc52381"},"source":["[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/biodatlab/deep-learning-skooldio/blob/master/student_notebooks/05_handwritten_gpu.ipynb)\n","\n","## **Thai-digit handwritten classification with Pytorch: Exploration**\n","\n","This notebook takes the previous classification code and implements the following:\n","- Training the model on GPU\n","- Save best validation model"]},{"cell_type":"markdown","id":"3aa56f94","metadata":{"id":"3aa56f94"},"source":["## **Download and clean the dataset from the repository**\n","\n","- We have downloaded the data from https://github.com/kittinan/thai-handwriting-number by cloning the repository\n","- Remove files that have character mismatch (as suggested by the the creator)\n","- Then, we put the cleaned data at https://github.com/biodatlab/deep-learning-skooldio"]},{"cell_type":"code","execution_count":null,"id":"SVgrt8iQN2bO","metadata":{"id":"SVgrt8iQN2bO"},"outputs":[],"source":["!git clone https://github.com/biodatlab/deep-learning-skooldio"]},{"cell_type":"code","execution_count":null,"id":"2ad2a443","metadata":{"id":"2ad2a443"},"outputs":[],"source":["import os\n","import os.path as op\n","from glob import glob\n","from pathlib import Path\n","import random\n","from PIL import Image\n","from collections import Counter\n","\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"id":"6wAWDTP7SN4X","metadata":{"id":"6wAWDTP7SN4X"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, ConcatDataset\n","from torchvision import transforms"]},{"cell_type":"code","execution_count":null,"id":"64ce2573","metadata":{"id":"64ce2573"},"outputs":[],"source":["directory = \"deep-learning-skooldio/\"\n","paths = glob(op.join(directory, \"thai-handwritten-dataset\", \"*\", \"*\"))\n","num_samples = len(paths)\n","print(\"Number of samples\", num_samples)"]},{"cell_type":"code","execution_count":null,"id":"6aa0f5b4","metadata":{"id":"6aa0f5b4"},"outputs":[],"source":["from tqdm.auto import tqdm\n","from sklearn.model_selection import train_test_split\n","import shutil\n","\n","train_paths, validation_paths = train_test_split(paths, test_size=0.1, random_state=42)\n","for i in range(10):\n","    os.makedirs(f\"data/train/{i}\", exist_ok=True)\n","    os.makedirs(f\"data/validation/{i}\", exist_ok=True)"]},{"cell_type":"code","execution_count":null,"id":"fe1d237b","metadata":{"id":"fe1d237b"},"outputs":[],"source":["def copy_to_destination(src_paths, dst_path: str = \"data/train/\"):\n","    for path in tqdm(src_paths):\n","        path = Path(path)\n","        if path.parent.name == \"10\":\n","            parent_dir = \"0\"\n","        else:\n","            parent_dir = path.parent.name\n","        shutil.copy(path, op.join(dst_path, parent_dir, path.name))"]},{"cell_type":"code","execution_count":null,"id":"af9064ae","metadata":{"id":"af9064ae"},"outputs":[],"source":["copy_to_destination(train_paths, \"data/train/\")\n","copy_to_destination(validation_paths, \"data/validation/\")"]},{"cell_type":"markdown","id":"ae55f494","metadata":{"id":"ae55f494"},"source":["## **Create a custom dataset and a dataloader**"]},{"cell_type":"code","execution_count":null,"id":"yyAx23w8PFLU","metadata":{"id":"yyAx23w8PFLU"},"outputs":[],"source":["# Create dataframe\n","train_df = pd.DataFrame({\"path\": glob(\"data/train/*/*\")})\n","val_df = pd.DataFrame({\"path\": glob(\"data/validation/*/*\")})\n","\n","# Create text column from path\n","train_df[\"text\"] = train_df[\"path\"].apply(lambda x: int(Path(x).parent.name))\n","val_df[\"text\"] = val_df[\"path\"].apply(lambda x: int(Path(x).parent.name))\n","\n","# Shape of dataframe\n","print(\"Number of train images = {}, number of validation images = {},\".format(train_df.shape, val_df.shape))"]},{"cell_type":"code","execution_count":null,"id":"09eb4140","metadata":{"id":"09eb4140"},"outputs":[],"source":["class ThaiDigitDataset(Dataset):\n","    def __init__(self, dataframe, transform=None):\n","        self.transform = transform\n","        self.dataframe = dataframe\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        label = int(self.dataframe['text'][idx])\n","        image = Image.open(self.dataframe['path'][idx])\n","        if self.transform:\n","            image = 1 - self.transform(image)\n","        return image, label"]},{"cell_type":"code","execution_count":null,"id":"fVep0nqyC2dJ","metadata":{"id":"fVep0nqyC2dJ"},"outputs":[],"source":["train_transform = transforms.Compose([\n","    transforms.Resize((28, 28)),\n","    transforms.Grayscale(),\n","    transforms.RandomAffine(degrees=(-15, 15), translate=(0.05, 0.1), scale=(1, 1)),\n","    transforms.ToTensor(),\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.Resize((28, 28)),\n","    transforms.Grayscale(),\n","    transforms.ToTensor(),\n","])"]},{"cell_type":"code","execution_count":null,"id":"f1175f91","metadata":{"id":"f1175f91"},"outputs":[],"source":["train_thaidigit_dataset = ThaiDigitDataset(train_df, transform=val_transform)\n","augmented_train_dataset = ThaiDigitDataset(train_df, transform=train_transform)\n","train_dataset = ConcatDataset([train_thaidigit_dataset, augmented_train_dataset])\n","val_dataset = ThaiDigitDataset(val_df, transform=val_transform)"]},{"cell_type":"code","execution_count":null,"id":"d4f83af9","metadata":{"id":"d4f83af9"},"outputs":[],"source":["train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)"]},{"cell_type":"markdown","id":"B9o4RAtbFV-a","metadata":{"id":"B9o4RAtbFV-a"},"source":["In this time we will train model using GPU (CUDA). We can check if cuda is available or not by using `torch.cuda.is_available()`."]},{"cell_type":"code","execution_count":null,"id":"GGt2B56zCuPX","metadata":{"id":"GGt2B56zCuPX"},"outputs":[],"source":["# TODO: check if CUDA is available, create device \"cuda\" or \"cpu\""]},{"cell_type":"code","execution_count":null,"id":"r61vWix7nfgl","metadata":{"id":"r61vWix7nfgl"},"outputs":[],"source":["# Modify the train function to train with cuda\n","def train(model, n_epochs, loss_function, optimizer, train_loader, validation_loader):\n","    training_logs = {\"train_loss\": [],  \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n","    print(\"-\"*80)\n","    model.train()\n","    # TODO: move model to device\n","\n","    for epoch in range(1, n_epochs+1):\n","        # training\n","        train_loss, correct = 0, 0\n","        for images, labels in train_loader:\n","            # Change device to cuda!\n","            # TODO: Move the data to GPU\n","\n","            pred = model(images)\n","            loss = loss_function(pred, labels)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","            correct += (pred.argmax(1) == labels).float().sum().item()\n","        # save training logs\n","        training_logs[\"train_loss\"].append(train_loss/ len(train_loader))\n","        training_logs[\"train_acc\"].append(correct / len(train_loader.dataset))\n","\n","        # validation\n","        model.eval()\n","        val_loss, correct = 0, 0\n","        for images, labels in validation_loader:\n","\n","            #!! Change device to cuda\n","            # TODO: Move the data to GPU\n","\n","            pred = model(images)\n","            val_loss += loss_function(pred, labels).item()\n","            correct += (pred.argmax(1) == labels).float().sum().item()\n","\n","        #!! Save best model\n","        # If training_logs[\"val_loss\"] is not empty\n","        if len(training_logs[\"val_loss\"]):\n","            # If the current validation loss is lower than the previous validation loss\n","            # So we save the model\n","            if min(training_logs[\"val_loss\"]) > (val_loss/ len(validation_loader)):\n","                save_path = \"thai_digit.pth\"\n","                torch.save(model.state_dict(), save_path)  # save model parameters\n","\n","        # save validation logs\n","        training_logs[\"val_loss\"].append(val_loss/ len(validation_loader))\n","        training_logs[\"val_acc\"].append(correct / len(validation_loader.dataset))\n","\n","        print(f\"Epochs {epoch}\".ljust(10),\n","              f\"train loss {training_logs['train_loss'][-1]:.5f}\",\n","              f\"train acc {training_logs['train_acc'][-1]:.5f}\",\n","\n","              f\"val loss {training_logs['val_loss'][-1]:.5f}\",\n","              f\"val acc {training_logs['val_acc'][-1]:.5f}\",\n","              )\n","        print(\"-\"*80)\n","    return model, training_logs"]},{"cell_type":"code","execution_count":null,"id":"_10LDBPaW9pv","metadata":{"id":"_10LDBPaW9pv"},"outputs":[],"source":["# evaluate function code from previous exercise\n","def evaluate(dataframe, model):\n","    model.eval()\n","    results = dataframe.copy()\n","    predictions = []\n","    for idx, row in results.iterrows():\n","        img = val_transform(Image.open(row.path))\n","        pred = model(1 - img)\n","        predictions.append(pred.argmax(1).item())\n","\n","    results[\"prediction\"] = predictions\n","    # Calculate accuracy\n","    accuracy = len(results[results.prediction == results.text]) / len(results)\n","    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n","    return results"]},{"cell_type":"code","execution_count":null,"id":"a8e819c7","metadata":{"id":"a8e819c7"},"outputs":[],"source":["class DropoutThaiDigit(nn.Module):\n","    def __init__(self):\n","        super(DropoutThaiDigit, self).__init__()\n","        self.layers = nn.Sequential(\n","            nn.Linear(28*28, 392),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(392, 196),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(196, 98),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(98, 10),\n","        )\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28 * 28)\n","        return self.layers(x)"]},{"cell_type":"code","execution_count":null,"id":"gJ-DLc1eSeDf","metadata":{"id":"gJ-DLc1eSeDf"},"outputs":[],"source":["n_epochs = 40\n","loss_fn = nn.CrossEntropyLoss()\n","model = DropoutThaiDigit()  # Initialize the model\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"]},{"cell_type":"code","execution_count":null,"id":"7Lh0XIxZFCOf","metadata":{"id":"7Lh0XIxZFCOf"},"outputs":[],"source":["model, augmented_model_history = train(\n","    model, n_epochs, loss_fn, optimizer, train_dataloader, val_dataloader\n",")"]},{"cell_type":"code","execution_count":null,"id":"nZkGkkWlIDDU","metadata":{"id":"nZkGkkWlIDDU"},"outputs":[],"source":["torch.save(model.state_dict(), \"thai_digit.pth\")"]},{"cell_type":"markdown","id":"L9QPc2C1FgHH","metadata":{"id":"L9QPc2C1FgHH"},"source":["## Use the model\n","\n","- You can use a similar inference as the CPU version\n","- However, do not forget to move the model and data to the same device (CPU or GPU)"]},{"cell_type":"code","execution_count":null,"id":"Wk5yqUX_FkhQ","metadata":{"id":"Wk5yqUX_FkhQ"},"outputs":[],"source":["img = Image.open(paths[100])\n","img = (1 - val_transform(img))\n","plt.title(\"Number: {}\".format(Path(paths[100]).parent.name))\n","plt.imshow(img.squeeze(0), cmap=\"gray\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"_uJTPdkwII3G","metadata":{"id":"_uJTPdkwII3G"},"outputs":[],"source":["# TODO: Try predicting using the model. It should give error since the data is not on the same device as the model"]},{"cell_type":"markdown","id":"bTUAEBkvLzIz","metadata":{"id":"bTUAEBkvLzIz"},"source":["There is a error in the code but why? <br />\n","Because the in train function, the data is not transfer to cuda device. <br />\n","So, we need to modify the train function to transfer the data to cuda device."]},{"cell_type":"code","execution_count":null,"id":"gDirc7WHITlN","metadata":{"id":"gDirc7WHITlN"},"outputs":[],"source":["# TODO: Move the data to the same device as the model\n"]},{"cell_type":"code","execution_count":null,"id":"iYnfka0yIruW","metadata":{"id":"iYnfka0yIruW"},"outputs":[],"source":["# TODO: detach the prediction from GPU to CPU\n"]},{"cell_type":"markdown","id":"8c58bf85","metadata":{"id":"8c58bf85"},"source":["And the rest is the same as before"]},{"cell_type":"markdown","id":"DTSwaZjKXs2-","metadata":{"id":"DTSwaZjKXs2-"},"source":["## **Load model and specify device**\n","\n","Use `map_location` to specify the location of loaded parameters\n","\n","```py\n","model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cuda\")))\n","```"]},{"cell_type":"code","execution_count":null,"id":"6V6E-8xxbR0A","metadata":{"id":"6V6E-8xxbR0A"},"outputs":[],"source":["# Load best model\n","model_path = \"thai_digit.pth\"\n","model = DropoutThaiDigit().cuda()  # initialize the model\n","# load the model weights, specifying the device to cuda\n","model.load_state_dict(\n","    torch.load(model_path, map_location=torch.device(\"cuda\"))\n",")"]},{"cell_type":"code","execution_count":null,"id":"jBv9MCwMKVHw","metadata":{"id":"jBv9MCwMKVHw"},"outputs":[],"source":["pred = model(img.to(device))"]},{"cell_type":"code","execution_count":null,"id":"-iWxRRTbKXxf","metadata":{"id":"-iWxRRTbKXxf"},"outputs":[],"source":["int(pred.detach().cpu().argmax(dim=1)) # detach from GPU"]},{"cell_type":"code","execution_count":null,"id":"6zFn2z3dLjLk","metadata":{"id":"6zFn2z3dLjLk"},"outputs":[],"source":["# Alternatively, load on CPU\n","model.cpu()\n","model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cpu\")))\n","pred = model(img)\n","int(pred.detach().cpu().argmax(dim=1)) # detach from GPU"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["3aa56f94","ae55f494"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"vscode":{"interpreter":{"hash":"63ce3f086f3d35aeaa98481dc3e6117e1ab6d0e955643b11e97a8ed761553864"}}},"nbformat":4,"nbformat_minor":5}